{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Preprocess images**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import random\nimport cv2\nimport math\n\n# Preprocessing functions\n\"\"\"\nremove the black borders of an img\n\"\"\"\ndef cut_black(img, tol=5):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    mask = img_gray > tol\n    idx = np.ix_(mask.any(1),mask.any(0))\n    return img[idx[0], idx[1], :]\n\n\n\"\"\"\nOnly take the center\n\"\"\"\ndef crop_center(img):\n    H, W = img.shape[0], img.shape[1]\n    if H == W:\n        return img\n    elif H > W:\n        return img[H//2-W//2:H//2+W//2, :, :]\n    else:\n        return img[:, W//2-H//2:W//2+H//2, :]\n        \n        \n\"\"\"\nAdjust brightness, scale to mean 100\n\"\"\"\ndef adjust_light(img):\n    brightness = np.mean(img)\n    return np.clip(100.0/brightness*img, 0, 255).astype(int)\n\n\n\"\"\"\nCrop image based off black pixels on diagon\n\"\"\"\ndef crop_diagonal(img):\n    img_diag = np.diagonal(img)\n    img_diag_gray = np.mean(img_diag, axis=0).astype('int32')\n    idx0 = np.argmax(img_diag_gray>5)\n    idx1 = len(img_diag_gray) - np.argmax(img_diag_gray[::-1]>5)\n    return img[idx0:idx1, idx0:idx1, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/aptos2019-blindness-detection/train_images\"\ntest_dir = \"../input/aptos2019-blindness-detection/test_images\"\ntrain_dir_processed = \"../train_processed\"\ntest_dir_processed = \"../test_processed\"\ntest_dir_nest = '../test_processed/test_processed'\nval_dir_processed = \"../val_processed\"\ntrain_label_file = \"../input/aptos2019-blindness-detection/train.csv\"\ntest_name_file = \"../input/aptos2019-blindness-detection/test.csv\"\ntest_pred_file = \"../input/aptos2019-blindness-detection/test_pred.csv\"\n\nif not os.path.exists(train_dir_processed):\n    os.mkdir(train_dir_processed)\nif not os.path.exists(test_dir_processed):\n    os.mkdir(test_dir_processed)\nif not os.path.exists(val_dir_processed):\n    os.mkdir(val_dir_processed)\nif not os.path.exists(test_dir_nest):\n    os.mkdir(test_dir_nest)\n\ntrain_labels = pd.read_csv(train_label_file)\nclasses = train_labels['diagnosis'].unique()\n\nglobal N, C, L\nN = train_labels.shape[0]\nC = classes.size\nL = 224\n\nprint(\"process train\")\nos.system('echo ' + 'process train')\ntrain_imgs = os.listdir(train_dir)\nfor train_img in train_imgs:\n    img = cv2.imread(os.path.join(train_dir, train_img))\n    img = cut_black(img)\n    img = crop_center(img)\n    img = adjust_light(img)\n    img = crop_diagonal(img)\n    cv2.imwrite(os.path.join(train_dir_processed, train_img), img)\n\nprint(\"process test\")\nos.system('echo ' + 'process test')\ntest_imgs = os.listdir(test_dir)\nfor test_img in test_imgs:\n    img = cv2.imread(os.path.join(test_dir, test_img))\n    img = cut_black(img)\n    img = crop_center(img)\n    img = adjust_light(img)\n    img = crop_diagonal(img)\n    cv2.imwrite(os.path.join(test_dir_nest, test_img), img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Organize training & validation data for fit_generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Organize data for fit_generator\n\n\"\"\"\nDivide data in directory into sub_dirs based on labels from csv file\n\"\"\"\ndef divide_data(train_dir, val_dir, train_labels, N, classes):\n#    C = classes.size\n    if not os.path.exists(val_dir):\n        os.mkdir(val_dir)\n    for c in classes:\n        os.mkdir(os.path.join(train_dir, str(c)))\n        os.mkdir(os.path.join(val_dir, str(c)))\n    \n    train_class = []\n    val_class = []\n    for i in range(N):\n        c = train_labels['diagnosis'][i]            # class\n        fn = train_labels['id_code'][i]+'.png'      # file name\n        if random.random() > 0.9:                   # move to val set\n            os.rename(os.path.join(train_dir, fn), os.path.join(val_dir, str(c), fn))\n            val_class.append(c)\n        else:\n            os.rename(os.path.join(train_dir, fn), os.path.join(train_dir, str(c), fn))\n            train_class.append(c)\n\n    class_weight = {c: 0 for c in classes}\n    max_N = 0\n    for c in classes:\n        N_train = len(os.listdir(os.path.join(train_dir, str(c))))\n        N_val = len(os.listdir(os.path.join(val_dir, str(c))))\n        class_weight[c] = N_train\n        if N_train > max_N:\n            max_N = N_train\n        print('Class ' + str(c) + ': N_train = ' + str(N_train) + ', N_val = ' + str(N_val))\n    for c in classes:\n        class_weight[c] = np.sqrt(max_N/class_weight[c])\n        \n    return np.array(train_class), np.array(val_class), class_weight\n\n\n\"\"\"\nCombine data in all subdirs of train & test dirs\n\"\"\"\ndef combine_data(train_dir, val_dir, classes):\n    for c in classes:\n        all_train = os.listdir(os.path.join(train_dir, str(c)))\n        all_val = os.listdir(os.path.join(val_dir, str(c)))\n        for fn in all_train:\n            os.rename(os.path.join(train_dir, str(c), fn), os.path.join(train_dir, fn))\n        for fn in all_val:\n            os.rename(os.path.join(val_dir, str(c), fn), os.path.join(train_dir, fn))\n        os.rmdir(os.path.join(train_dir, str(c)))\n        os.rmdir(os.path.join(val_dir, str(c)))\n    os.rmdir(val_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide train & val data\ntrain_labels = pd.read_csv(train_label_file)\nclasses = train_labels['diagnosis'].unique()\nclasses = np.sort(classes)\n\nglobal N, C, L\nN = train_labels.shape[0]\nC = classes.size\nL = 224\n\ntrain_class, val_class, class_weight = divide_data(train_dir_processed, val_dir_processed, train_labels, N, classes)\nprint(class_weight)\nos.system('echo ' + str(class_weight))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.5 Optional re-divide**"},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_data(train_dir_processed, val_dir_processed, classes)\ntrain_class, val_class, class_weight = divide_data(train_dir_processed, val_dir_processed, train_labels, N, classes)\nprint(class_weight)\nos.system('echo ' + str(class_weight))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Build model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\n\n\"\"\"\nSingle conv layer in CNN model\n\"\"\"\ndef conv_layer(x_in, filters, kernel_dim, drop_rate=0.0, batch_norm=True, max_pool=True):\n    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=(kernel_dim,kernel_dim), strides=(1,1), padding='same',\n               kernel_initializer='he_normal')(x_in)\n    x = tf.keras.layers.Activation('relu')(x)\n    if drop_rate > 0.0:\n        x = tf.keras.layers.Dropout(drop_rate)(x)\n    if batch_norm:\n        x = tf.keras.layers.BatchNormalization()(x)\n    if max_pool:\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n    return x\n    \n\n\"\"\"\nSingle dense/FC layer in CNN model\n\"\"\"\ndef dense_layer(x_in, units, activation='tanh', drop_rate=0.0):\n    x = tf.keras.layers.Dense(units, activation=activation)(x_in)\n    if drop_rate > 0.0:\n        x = tf.keras.layers.Dropout(rate = drop_rate)(x)\n    return x\n\n\"\"\"\nCustom loss function\n\"\"\"\ndef custom_loss(y_true, y_pred):\n    class_true = K.cast(K.expand_dims(K.argmax(y_true, axis=-1), axis=-1), 'float32')   # y_true is one-hot\n    i = np.array([[0, 1, 2, 3, 4]]).astype('float32')\n    alpha = K.square(i - class_true) / 4.0\n    # cross entropy\n    loss1 = -K.sum(y_true * K.log(y_pred), axis=-1)\n    # additional term to penalize worse predictions\n    loss2 = -K.sum(alpha * (1-y_true) * K.log(1-y_pred), axis=-1)\n    \n    return loss1+loss2\n\n\n\"\"\"\nCustom eval metric: quadratic weighted kappa\n\"\"\"\ndef qwk(y_true, y_pred):\n    # compute confution matrix\n    y_true_label = K.argmax(y_true, axis=-1)    # one-hot to class number\n    y_pred_label = K.argmax(y_pred, axis=-1)\n    confusion = tf.math.confusion_matrix(y_true_label, y_pred_label, num_classes=5, dtype='float32')\n    \n    # compute quadratic weight\n    alpha = np.square([[i-j for i in range(5)] for j in range(5)]).astype('float32')\n\n    # compute observed and expected matrix\n    observed = confusion/tf.reduce_sum(confusion)  # count -> distribution\n    P_pred = tf.reduce_sum(confusion, axis=0)/tf.reduce_sum(confusion)\n    P_true = tf.reduce_sum(confusion, axis=1)/tf.reduce_sum(confusion)\n    expected = tf.tensordot(P_true, P_pred, axes=0)\n    \n    # compute kappa\n    kappa = 1 - tf.reduce_sum(tf.multiply(alpha, observed))/tf.reduce_sum(tf.multiply(alpha, expected))\n    return kappa\n\n\n\"\"\"\nUse transfer learning\n\"\"\"\ndef transfer_model():\n    base_model = tf.keras.applications.VGG16(input_shape=(L,L,3), weights='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\n#    base_model = tf.keras.applications.InceptionResNetV2(input_shape=(L,L,3), weights='imagenet', include_top=False)\n#    base_model = tf.keras.applications.ResNet50(input_shape=(L,L,3), weights='imagenet', include_top=False)\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = base_model.output\n    \n    # dense layers\n#    x = tf.keras.layers.Flatten()(x)\n#    x = tf.keras.layers.GlobalAveragePooling2D()(x)    # faster processing, omit spacial, vessel leakage can happen anywhere\n    x = tf.keras.layers.GlobalMaxPooling2D()(x)         # you only need to find certain features once, other areas can be blank\n#    x = dense_layer(x, units=512, activation='elu', drop_rate=0.25)\n    x = dense_layer(x, units=64, activation='tanh', drop_rate=0.4)\n    \n    # class pred\n    x_out = tf.keras.layers.Dense(5, activation='softmax')(x)\n    \n    # compile model\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=x_out)\n#    sgd = tf.keras.optimizers.SGD(learning_rate=0.001)\n    adam = tf.keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n    \n#    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n    model.compile(optimizer=adam, loss=custom_loss, metrics=['acc', qwk])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Train model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nGenerate (and augment) data for model\n\"\"\"\ndef gen_data(train_dir, val_dir, batch_size):\n    print(\"Train set:\")\n    train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n                                       #rotation_range=360,  # an eyeball at any angle is still the same\n                                       horizontal_flip=True,        # left/right eye symmetry\n                                       vertical_flip=True)          # left/right eye symmetry\n                                       #brightness_range=(0.5, 1))   # there are dark imgs\n    train_generator = train_datagen.flow_from_directory(train_dir,\n                                                        batch_size=batch_size,\n                                                        class_mode='categorical',\n                                                        target_size=(L, L))\n    print(\"Val set:\")\n    val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n    val_generator = val_datagen.flow_from_directory(val_dir,\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    target_size=(L, L))\n    \n    return train_generator, val_generator\n\n\"\"\"\nDisplay training history\n\"\"\"\ndef show_history(history):\n    acc=history.history['acc']\n    val_acc=history.history['val_acc']\n    qwk=history.history['qwk']\n    val_qwk=history.history['val_qwk']\n    loss=history.history['loss']\n    val_loss=history.history['val_loss']\n    \n    epochs = list(range(1, len(acc)+1))\n    plt.figure(1)\n    plt.plot(epochs, loss, 'b', epochs, val_loss, 'r')\n    plt.title('loss')\n    plt.legend(('train', 'val'))\n    \n    plt.figure(2)\n    plt.plot(epochs, acc, 'b', epochs, val_acc, 'r')\n    plt.title('accuracy')\n    plt.legend(('train', 'val'))\n    \n    plt.figure(3)\n    plt.plot(epochs, qwk, 'b', epochs, val_qwk, 'r')\n    plt.title('weighted kappa')\n    plt.legend(('train', 'val'))\n\n    plt.figure(4)\n    plt.plot(loss, qwk)\n    plt.title('train: qwk vs loss')\n    \n    plt.figure(5)\n    plt.plot(val_loss, val_qwk)\n    plt.title('train: qwk vs loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen, val_gen = gen_data(train_dir_processed, val_dir_processed, batch_size=128)\n\nmodel = transfer_model()\nmodel.summary()\ncallbacks = [#tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7),\n             tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',  min_delta=0.0004,\n                                                  patience=3, factor=0.5, min_lr=1e-5,  mode='auto', verbose=1),\n             tf.keras.callbacks.ModelCheckpoint(filepath = 'weights-best.hdf5', \n                                                monitor='val_loss', save_best_only=True)]\n\nos.system('echo ' + 'training')\nhistory = model.fit_generator(train_gen,\n                              validation_data = val_gen,\n                              steps_per_epoch=math.ceil(train_gen.samples*2/train_gen.batch_size),\n                              class_weight=class_weight,\n                              epochs = 60,    # takes 8:47 to run 65 epochs. any more the kernel will fail\n                              validation_steps=math.ceil(val_gen.samples/val_gen.batch_size),\n                              callbacks = callbacks,\n                              #use_multiprocessing=False,\n                              verbose = 1)\n\nshow_history(history)\n\nval_pred = model.predict_generator(val_gen, workers=1)    # workers!=1 will mess up the order\nval_pred_class = np.argmax(val_pred, axis=1)\nplt.figure(6)\nplt.hist(val_pred_class, bins=5)\nplt.title('val pred distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Generate test set results**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nWrite test set output\n\"\"\"\ndef output_test(test_dir, output_filename):\n    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n    test_gen = test_datagen.flow_from_directory(test_dir, target_size=(L, L))\n    test_pred = model.predict_generator(test_gen, workers=1)    # workers!=1 will mess up the order\n    test_pred_class = np.argmax(test_pred, axis=1)\n    test_files = test_gen.filenames\n    id_codes = ['']*len(test_files)\n    for i in range(len(test_files)):\n        id_codes[i] = test_files[i][15:-4]\n    \n    test_df = pd.DataFrame(data={'id_code': id_codes, 'diagnosis': test_pred_class})\n    test_df.to_csv(output_filename, index=False)\n\noutput_filename = 'submission.csv'\noutput_test(test_dir_processed, output_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_class = pd.read_csv(output_filename)\ntest_pred_class.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(test_pred_class['diagnosis'], bins=5)\nplt.title('test pred distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}